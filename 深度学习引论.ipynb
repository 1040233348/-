{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b429294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb5a77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26032, 32, 32, 3), (26032, 1), (73257, 32, 32, 3), (73257, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = scio.loadmat('dataset/test.mat')\n",
    "train = scio.loadmat('dataset/train.mat')\n",
    "test_x = np.array(test['X'])\n",
    "test_y = np.array(test['y'])\n",
    "train_x = np.array(train['X'])\n",
    "train_y = np.array(train['y'])\n",
    "\n",
    "test_x = np.transpose(test_x, (3, 0, 1, 2))\n",
    "train_x = np.transpose(train_x, (3, 0, 1, 2))\n",
    "\n",
    "train_x = train_x.astype(float)\n",
    "test_x = test_x.astype(float)\n",
    "test_x.shape, test_y.shape, train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d41b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_y)):\n",
    "    if test_y[i] == 10:\n",
    "        test_y[i] = 0\n",
    "for i in range(len(train_y)):\n",
    "    if train_y[i] == 10:\n",
    "        train_y[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea290f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_gray(rgb_image):\n",
    "    gray_w = np.array([0.299, 0.587, 0.114]).reshape(3,1)\n",
    "    gray_image = np.matmul(rgb_image, gray_w)\n",
    "    return gray_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "137cc71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73257, 32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_gray = np.zeros((train_x.shape[0], 32, 32, 1))\n",
    "test_x_gray = np.zeros((test_x.shape[0], 32, 32, 1))\n",
    "\n",
    "for i in range(train_x.shape[0]):\n",
    "    train_x_gray[i] = rgb_to_gray(train_x[i])\n",
    "\n",
    "for i in range(test_x.shape[0]):\n",
    "    test_x_gray[i] = rgb_to_gray(test_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f05bcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(image_data):\n",
    "    flattened_data = image_data.reshape((-1, 2))\n",
    "    min_vals = np.min(flattened_data, axis=0)\n",
    "    max_vals = np.max(flattened_data, axis=0)\n",
    "\n",
    "    scaled_data = (flattened_data - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "    scaled_image_data = scaled_data.reshape(image_data.shape)\n",
    "    return scaled_image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3473d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x_gray.shape[0]):\n",
    "    train_x_gray[i] = min_max_scaling(train_x_gray[i])\n",
    "for i in range(test_x_gray.shape[0]):\n",
    "    test_x_gray[i] = min_max_scaling(test_x_gray[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a797ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.where(self.input <= 0, 0, input)\n",
    "        return self.output\n",
    "\n",
    "    def backprop(self, theta):\n",
    "        d = np.where(self.input > 0, 1, 0)\n",
    "        return d * theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59da57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    def __init__(self, params, lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = [np.zeros_like(param) for param in params]\n",
    "        self.v = [np.zeros_like(param) for param in params]\n",
    "        self.t = 0\n",
    "        self.params = params  \n",
    "\n",
    "    def update(self, grads):\n",
    "        self.t += 1\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * grad\n",
    "            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * (grad ** 2)\n",
    "            m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n",
    "            v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n",
    "            update = self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "            self.params[i] -= update  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf6899b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3x3:\n",
    "    def __init__(self, c, num_filters) -> None:\n",
    "        self.input_c = c\n",
    "        self.num_filters = num_filters\n",
    "        self.filters = np.random.randn(num_filters, 3, 3, self.input_c) * np.sqrt(2 / (3 * 3 * self.input_c))\n",
    "\n",
    "\n",
    "    def img_iterator(self, image):\n",
    "        h, w, c = image.shape\n",
    "        for i in range(h - 2):\n",
    "            for j in range(w - 2):\n",
    "                im_region = image[i:(i + 3), j:(j + 3), :]\n",
    "                yield i, j, im_region\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.input_h, self.input_w, self.input_c = self.input.shape\n",
    "        self.output = np.zeros((self.input_h - 2, self.input_w - 2, self.num_filters))\n",
    "\n",
    "        for i, j, img in self.img_iterator(input):\n",
    "            # img(3, 3, c) * filters(n, 3, 3, c) = (n, 3, 3, c)\n",
    "            self.output[i, j] = np.sum(img * self.filters, axis=(1, 2, 3))\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    def backprop(self, next_theta):\n",
    "        theta = np.zeros((self.input_h, self.input_w, self.input_c))\n",
    "        delta = np.zeros(self.filters.shape)\n",
    "\n",
    "        for i, j, img in self.img_iterator(self.input):\n",
    "            for f in range(self.num_filters):\n",
    "                delta[f] += next_theta[i, j, f] * img\n",
    "        \n",
    "        for f in range(self.num_filters):\n",
    "            for i in range(self.input_h - 2):\n",
    "                for j in range(self.input_w - 2):\n",
    "                    theta[i:(i + 3), j:(j + 3)] += next_theta[i, j, f] * self.filters[f]          \n",
    "        # self.filters -= lr * delta\n",
    "        return theta, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a53b1705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2*2的最大值池化\n",
    "class MaxPool:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "    def img_iterator(self, image):\n",
    "        input_h, input_w, input_c = image.shape\n",
    "        output_h, output_w = input_h//2, input_w//2\n",
    "\n",
    "        for i in range(output_h):\n",
    "            for j in range(output_w):\n",
    "                im_region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\n",
    "                yield i, j, im_region\n",
    "    \n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.input_h, self.input_w, self.input_c = self.input.shape\n",
    "        self.output_h, self.output_w = self.input_h//2, self.input_w//2\n",
    "        self.output = np.zeros((self.output_h, self.output_w, self.input_c))\n",
    "\n",
    "        for i, j, img in self.img_iterator(self.input):\n",
    "            self.output[i, j] = np.max(img, axis=(0, 1))      \n",
    "        return self.output\n",
    "    \n",
    "\n",
    "    def backprop(self, next_theta):\n",
    "        theta = np.zeros((self.input_h, self.input_w, self.input_c))\n",
    "        for i, j, img in self.img_iterator(self.input):\n",
    "            h, w, c = img.shape   \n",
    "            a_max = np.max(img, axis=(0, 1))\n",
    "            \n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for c2 in range(c):\n",
    "                        if img[i2, j2, c2] == a_max[c2]:\n",
    "                            theta[i * 2 + i2, j * 2 + j2, c2] = next_theta[i, j, c2]\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43642fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, input_size, output_size) -> None:\n",
    "        self.w = np.random.randn(output_size, input_size) * np.sqrt(2 / input_size)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input \n",
    "        self.output = np.matmul(self.w, self.input) \n",
    "        return self.output\n",
    "    \n",
    "    \n",
    "    def backprop(self, next_theta):\n",
    "        theta = np.dot(self.w.T, next_theta)\n",
    "        delta = np.outer(next_theta, self.input)\n",
    "        # self.w = self.w - lr * delta\n",
    "        return theta, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f120c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def forward(self, input): \n",
    "        input_exp = np.exp(input)\n",
    "        self.output = input_exp / np.sum(input_exp, axis=0)\n",
    "        return self.output\n",
    "    \n",
    "    \n",
    "    def getloss(self, label):\n",
    "        self.label_onehot = np.zeros_like(self.output)              \n",
    "        self.label_onehot[label] = 1\n",
    "        loss = -np.sum(np.log(self.output) * self.label_onehot)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def backprop(self):\n",
    "        theta = self.output - self.label_onehot\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85bb6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv3x3(1, 32) # -> 30*30*32\n",
    "relu1 = Relu()\n",
    "pool1 = MaxPool()   # -> 15*15*32\n",
    "conv2 = Conv3x3(32, 64) # -> 13*13*64\n",
    "relu2 = Relu()\n",
    "conv3 = Conv3x3(64, 64) # -> 11*11*64\n",
    "relu3 = Relu()\n",
    "pool3 = MaxPool()   # -> 5*5*64\n",
    "\n",
    "dense1 = Dense(1600, 512)\n",
    "relu4 = Relu()\n",
    "dense2 = Dense(512, 10)\n",
    "\n",
    "softmax = Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ce8ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = AdamOptimizer(params=[conv1.filters, conv2.filters, conv3.filters, dense1.w, dense2.w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddcb2905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(img, label):\n",
    "    a = conv1.forward(img)\n",
    "    a = relu1.forward(a)\n",
    "    a = pool1.forward(a)\n",
    "    a = conv2.forward(a)\n",
    "    a = relu2.forward(a)\n",
    "    a = conv3.forward(a)\n",
    "    a = relu3.forward(a)\n",
    "    a = pool3.forward(a)\n",
    "    \n",
    "    a = a.reshape(-1)\n",
    "\n",
    "    a = dense1.forward(a)\n",
    "    a = relu4.forward(a)\n",
    "    a = dense2.forward(a)\n",
    "\n",
    "    out = softmax.forward(a)\n",
    "\n",
    "    loss = softmax.getloss(label)\n",
    "    ans = np.argmax(out)\n",
    "    acc = 1 if ans == label else 0\n",
    "    return out, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcf8441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(img, label):\n",
    "    out, loss, acc = forward(img, label)\n",
    " \n",
    "    # 反向传播\n",
    "    theta = softmax.backprop() \n",
    " \n",
    "    theta, dense2_grad = dense2.backprop(theta)\n",
    "    theta = relu4.backprop(theta) \n",
    "    theta, dense1_grad = dense1.backprop(theta)\n",
    "\n",
    "    theta = theta.reshape(5,5,64)\n",
    "\n",
    "    theta = pool3.backprop(theta)\n",
    "    theta = relu3.backprop(theta) \n",
    "    theta, conv3_grad = conv3.backprop(theta)\n",
    "    theta = relu2.backprop(theta) \n",
    "    theta, conv2_grad = conv2.backprop(theta)\n",
    "    theta = pool1.backprop(theta)\n",
    "    theta = relu1.backprop(theta) \n",
    "    theta, conv1_grad = conv1.backprop(theta)\n",
    "    adam_optimizer.update([conv1_grad, conv2_grad, conv3_grad, dense1_grad, dense2_grad])\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10278d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "best_params = [conv1.filters.copy(), conv2.filters.copy(), conv3.filters.copy(), dense1.w.copy(), dense2.w.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a30af71f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1 ---\n",
      "[Step 1000] Past 1000 steps: Average Loss 2.0710472271963782 | Accuracy: 29.30%\n",
      "[Step 2000] Past 1000 steps: Average Loss 1.2336045383356316 | Accuracy: 59.70%\n",
      "[Step 3000] Past 1000 steps: Average Loss 0.9870197622522251 | Accuracy: 70.60%\n",
      "[Step 4000] Past 1000 steps: Average Loss 0.8287701501933068 | Accuracy: 74.90%\n",
      "[Step 5000] Past 1000 steps: Average Loss 0.8730084303513184 | Accuracy: 72.30%\n",
      "[Step 6000] Past 1000 steps: Average Loss 0.8392607043791046 | Accuracy: 75.10%\n",
      "[Step 7000] Past 1000 steps: Average Loss 0.7712740253156015 | Accuracy: 77.00%\n",
      "[Step 8000] Past 1000 steps: Average Loss 0.647756526392497 | Accuracy: 79.10%\n",
      "[Step 9000] Past 1000 steps: Average Loss 0.7028852825737771 | Accuracy: 78.50%\n",
      "[Step 10000] Past 1000 steps: Average Loss 0.696733508193185 | Accuracy: 78.60%\n",
      "[Step 11000] Past 1000 steps: Average Loss 0.5849927179708961 | Accuracy: 81.60%\n",
      "[Step 12000] Past 1000 steps: Average Loss 0.7163546743914582 | Accuracy: 79.10%\n",
      "[Step 13000] Past 1000 steps: Average Loss 0.6464303486585994 | Accuracy: 79.70%\n",
      "[Step 14000] Past 1000 steps: Average Loss 0.6103948263137166 | Accuracy: 80.30%\n",
      "[Step 15000] Past 1000 steps: Average Loss 0.6750283528240414 | Accuracy: 78.60%\n",
      "[Step 16000] Past 1000 steps: Average Loss 0.6247843856514046 | Accuracy: 81.10%\n",
      "[Step 17000] Past 1000 steps: Average Loss 0.6218525229783067 | Accuracy: 81.10%\n",
      "[Step 18000] Past 1000 steps: Average Loss 0.6871477778925346 | Accuracy: 79.80%\n",
      "[Step 19000] Past 1000 steps: Average Loss 0.5827921336987999 | Accuracy: 81.70%\n",
      "[Step 20000] Past 1000 steps: Average Loss 0.570312407172575 | Accuracy: 82.90%\n",
      "[Step 21000] Past 1000 steps: Average Loss 0.7053328530046141 | Accuracy: 80.10%\n",
      "[Step 22000] Past 1000 steps: Average Loss 0.6621504136871296 | Accuracy: 80.20%\n",
      "[Step 23000] Past 1000 steps: Average Loss 0.6380996898152104 | Accuracy: 82.10%\n",
      "[Step 24000] Past 1000 steps: Average Loss 0.5102608676919276 | Accuracy: 84.90%\n",
      "[Step 25000] Past 1000 steps: Average Loss 0.5731998949777691 | Accuracy: 83.30%\n",
      "[Step 26000] Past 1000 steps: Average Loss 0.5770222770023181 | Accuracy: 83.30%\n",
      "[Step 27000] Past 1000 steps: Average Loss 0.5579814182875241 | Accuracy: 82.90%\n",
      "[Step 28000] Past 1000 steps: Average Loss 0.5248154402422073 | Accuracy: 84.80%\n",
      "[Step 29000] Past 1000 steps: Average Loss 0.6047081259364441 | Accuracy: 82.40%\n",
      "[Step 30000] Past 1000 steps: Average Loss 0.576039155852693 | Accuracy: 84.60%\n",
      "[Step 31000] Past 1000 steps: Average Loss 0.5546969413629405 | Accuracy: 83.00%\n",
      "[Step 32000] Past 1000 steps: Average Loss 0.5325711291680508 | Accuracy: 84.80%\n",
      "[Step 33000] Past 1000 steps: Average Loss 0.5552734404257886 | Accuracy: 83.60%\n",
      "[Step 34000] Past 1000 steps: Average Loss 0.5309020785740624 | Accuracy: 84.00%\n",
      "[Step 35000] Past 1000 steps: Average Loss 0.5192939338129737 | Accuracy: 83.40%\n",
      "[Step 36000] Past 1000 steps: Average Loss 0.5462222199875888 | Accuracy: 84.80%\n",
      "[Step 37000] Past 1000 steps: Average Loss 0.4842894345059184 | Accuracy: 86.70%\n",
      "[Step 38000] Past 1000 steps: Average Loss 0.5570626285866365 | Accuracy: 84.50%\n",
      "[Step 39000] Past 1000 steps: Average Loss 0.48535422132701095 | Accuracy: 85.80%\n",
      "[Step 40000] Past 1000 steps: Average Loss 0.6311905656145246 | Accuracy: 81.90%\n",
      "[Step 41000] Past 1000 steps: Average Loss 0.5134985931234372 | Accuracy: 84.80%\n",
      "[Step 42000] Past 1000 steps: Average Loss 0.48370208704828704 | Accuracy: 84.30%\n",
      "[Step 43000] Past 1000 steps: Average Loss 0.5258782892788779 | Accuracy: 83.20%\n",
      "[Step 44000] Past 1000 steps: Average Loss 0.483448764511081 | Accuracy: 85.30%\n",
      "[Step 45000] Past 1000 steps: Average Loss 0.5587853619301475 | Accuracy: 84.10%\n",
      "[Step 46000] Past 1000 steps: Average Loss 0.517185070499323 | Accuracy: 84.90%\n",
      "[Step 47000] Past 1000 steps: Average Loss 0.464931757341596 | Accuracy: 85.00%\n",
      "[Step 48000] Past 1000 steps: Average Loss 0.4555354739335063 | Accuracy: 87.20%\n",
      "[Step 49000] Past 1000 steps: Average Loss 0.5445354084362682 | Accuracy: 85.40%\n",
      "[Step 50000] Past 1000 steps: Average Loss 0.4916348512850859 | Accuracy: 84.30%\n",
      "[Step 51000] Past 1000 steps: Average Loss 0.5347091278868451 | Accuracy: 86.00%\n",
      "[Step 52000] Past 1000 steps: Average Loss 0.5203891239574004 | Accuracy: 84.30%\n",
      "[Step 53000] Past 1000 steps: Average Loss 0.5609332501019458 | Accuracy: 84.60%\n",
      "[Step 54000] Past 1000 steps: Average Loss 0.5106381738238598 | Accuracy: 83.70%\n",
      "[Step 55000] Past 1000 steps: Average Loss 0.5299137339058478 | Accuracy: 85.60%\n",
      "[Step 56000] Past 1000 steps: Average Loss 0.49606322653825086 | Accuracy: 85.50%\n",
      "[Step 57000] Past 1000 steps: Average Loss 0.46060571474077194 | Accuracy: 86.20%\n",
      "[Step 58000] Past 1000 steps: Average Loss 0.4825383680461032 | Accuracy: 85.90%\n",
      "[Step 59000] Past 1000 steps: Average Loss 0.5191073180513682 | Accuracy: 85.40%\n",
      "[Step 60000] Past 1000 steps: Average Loss 0.4909938080661675 | Accuracy: 83.80%\n",
      "[Step 61000] Past 1000 steps: Average Loss 0.5162470051015894 | Accuracy: 85.90%\n",
      "[Step 62000] Past 1000 steps: Average Loss 0.5446564893769316 | Accuracy: 83.70%\n",
      "[Step 63000] Past 1000 steps: Average Loss 0.4417613900391938 | Accuracy: 88.10%\n",
      "[Step 64000] Past 1000 steps: Average Loss 0.5570618967482635 | Accuracy: 84.60%\n",
      "[Step 65000] Past 1000 steps: Average Loss 0.5884325816283474 | Accuracy: 84.20%\n",
      "[Step 66000] Past 1000 steps: Average Loss 0.4380836185960871 | Accuracy: 87.00%\n",
      "[Step 67000] Past 1000 steps: Average Loss 0.4940549112170855 | Accuracy: 85.70%\n",
      "[Step 68000] Past 1000 steps: Average Loss 0.4358161790718578 | Accuracy: 87.30%\n",
      "[Step 69000] Past 1000 steps: Average Loss 0.5158627701749392 | Accuracy: 85.50%\n",
      "[Step 70000] Past 1000 steps: Average Loss 0.48839070526777817 | Accuracy: 86.20%\n",
      "[Step 71000] Past 1000 steps: Average Loss 0.45597003911663225 | Accuracy: 87.20%\n",
      "[Step 72000] Past 1000 steps: Average Loss 0.40914429731111057 | Accuracy: 87.20%\n",
      "[Step 73000] Past 1000 steps: Average Loss 0.5384638636977105 | Accuracy: 83.50%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    print('--- Epoch %d ---' % (epoch + 1))\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    for i, (img, label) in enumerate(zip(train_x_gray, train_y)):\n",
    "        if i > 0 and i % 1000 == 999:\n",
    "            print(f'[Step {i + 1}] Past 1000 steps: Average Loss {loss / 1000} | Accuracy: {num_correct / 1000 :.2%}')\n",
    "            \n",
    "            current_accuracy = num_correct/1000\n",
    "            if current_accuracy > best_accuracy:\n",
    "                best_accuracy = current_accuracy\n",
    "                best_params = [conv1.filters.copy(), conv2.filters.copy(), conv3.filters.copy(), dense1.w.copy(), dense2.w.copy()]\n",
    "            \n",
    "            loss = 0\n",
    "            num_correct = 0\n",
    "\n",
    "        l, acc = train(img, label)\n",
    "        loss += l\n",
    "        num_correct += acc\n",
    "\n",
    "conv1.filters, conv2.filters, conv3.filters, dense1.w, dense2.w = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model_params.pkl', 'wb') as file:\n",
    "    pickle.dump(best_params, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c39c4a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4972428456464234\n",
      "Test Accuracy: 0.8567916410571604\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "num_correct = 0\n",
    "for img, label in zip(test_x_gray, test_y):\n",
    "    _, l, acc = forward(img, label)\n",
    "    loss += l\n",
    "    num_correct += acc\n",
    " \n",
    "num_tests = len(test_x)\n",
    "print('Test Loss:', loss / num_tests)\n",
    "print('Test Accuracy:', num_correct / num_tests)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
